# 4. Large Language Model

Date: 2024-11-14

## Status

Accepted

## Context

A simple machine learning models, which struggle with context, ambiguity, and natural language while interacting with humans even after having written big amount of code. However, by using LLMs, applications can perform a wide range of language-related tasksâ€”like answering questions, summarizing text, automating customer support and generating content. Thereby enhancing productivity, improving user experiences, and automating complex workflows.

## Decision

We have decided to use Open AI gpt model, as they are a top choice for developers and businesses looking for powerful, versatile, and easy-to-integrate AI solutions. Their state-of-the-art performance, robust ecosystem, and continuous innovation set them apart from other LLM alternatives, making them highly effective for a wide range of applications.

## Consequences

Using Open AI gpt we found its cutting-edge performance in understanding and generating human-like text. They excel in various NLP tasks, including text completion, summarization, translation, and answering complex questions. Models are trained on a diverse and extensive dataset, enabling them to generate more accurate, coherent, and contextually relevant responses compared to other models. 
Vast community of developers, resources, tutorials, and pre-built integrations available for OpenAI GPT, which can significantly speed up your development process.


However some cons of using gpt are as follows:

 1) It's expensive, especially for large-scale usage, making it less suitable for budget-constrained projects.
 
 2) The model operates as a black box, limiting control and customization, and while some fine-tuning is possible, it isn't as flexible as open-source alternatives.

 3) GPT models can also produce inaccurate or biased responses, sometimes generating misleading information confidently. 

 4) OpenAI's API raises data privacy concerns, especially for sensitive information, and applications can face rate limits and latency issues, which may impact performance during high demand. 
 
 These factors require careful consideration, especially for projects that prioritize cost efficiency, control, and data security.